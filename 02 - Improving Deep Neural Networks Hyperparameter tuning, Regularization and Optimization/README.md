# Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization from Deep Learning Specialization
This repository contains all programming assignments solutions for the [Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization](https://www.coursera.org/learn/deep-neural-network?specialization=deep-learning) course on [Coursera](https://www.coursera.org) taught by the legendary prof. Andrew Ng.

This specialization cover:
- Artificial Neural Networks and Deep Learning
- Hyperparameter Optimization
- Understand industry best-practices for building deep learning applications. 
- Be able to effectively use the common neural network "tricks", including initialization, L2 and dropout regularization, Batch normalization, gradient checking, 
- Be able to implement and apply a variety of optimization algorithms, such as mini-batch gradient descent, Momentum, RMSprop and Adam, and check for their convergence. 
- Understand new best-practices for the deep learning era of how to set up train/dev/test sets and analyze bias/variance
- Be able to implement a neural network in TensorFlow. 

## Certificate of Completion
You can see the [Certificate of Completion](https://github.com/AlessandroCorradini/Certificates/blob/master/Coursera%20-%20Improving%20Deep%20Neural%20Networks%20-%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20-%20Deeplearning.ai.pdf) and other certificates in my [Certificates Repo](https://github.com/AlessandroCorradini/Certificates) that contains all my certificates obtained through my journey as a self-made Data Science and better developer.

<br/>

### ⚠️ Disclaimer ⚠️
**Please, don't fork or copy this repository.**

**The Deep Learning Specialization offered by Deeplearning.ai, is a intermediate level course. Data Science is one of the hardest subfield of Computer Science and requires a lot of study and hard work.**

